{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation, Dropout,Flatten,Dense\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Constant\n",
    "img_width,img_height = 150,150  # Setting the image height and weight as 150*150\n",
    " \n",
    "train_data_dir = \"data/train\"   # Traing images are taken from data folder\n",
    "validation_data_dir = \"data/test\" # Testing images are taken from data folder\n",
    "train_samples=900  # 900 images will feeded to the model as traing set\n",
    "test_samples=240   # 240 images will feeded to the model as test set\n",
    "epochs=50          # 50 epochs will be occur\n",
    "batch_size=20      # 20 images will be feeded at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 926 images belonging to 3 classes.\n",
      "Found 249 images belonging to 3 classes.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,643\n",
      "Trainable params: 1,212,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 66s 1s/step - loss: 0.6885 - accuracy: 0.6588 - val_loss: 0.6292 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 65s 1s/step - loss: 0.6113 - accuracy: 0.6749 - val_loss: 0.6411 - val_accuracy: 0.6914\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 66s 1s/step - loss: 0.5028 - accuracy: 0.7615 - val_loss: 0.4573 - val_accuracy: 0.7540\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 64s 1s/step - loss: 0.4153 - accuracy: 0.8073 - val_loss: 0.4316 - val_accuracy: 0.7962\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 63s 1s/step - loss: 0.3089 - accuracy: 0.8736 - val_loss: 0.2892 - val_accuracy: 0.8428\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 67s 1s/step - loss: 0.2318 - accuracy: 0.9086 - val_loss: 0.3404 - val_accuracy: 0.7991\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 72s 2s/step - loss: 0.1595 - accuracy: 0.9381 - val_loss: 0.3152 - val_accuracy: 0.8690\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 62s 1s/step - loss: 0.1494 - accuracy: 0.9451 - val_loss: 0.2927 - val_accuracy: 0.8646\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 63s 1s/step - loss: 0.1256 - accuracy: 0.9480 - val_loss: 0.2423 - val_accuracy: 0.8850\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 64s 1s/step - loss: 0.1005 - accuracy: 0.9574 - val_loss: 1.1577 - val_accuracy: 0.7496\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 62s 1s/step - loss: 0.0843 - accuracy: 0.9786 - val_loss: 0.3457 - val_accuracy: 0.8326\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.0743 - accuracy: 0.9722 - val_loss: 0.2918 - val_accuracy: 0.7656\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 70s 2s/step - loss: 0.0671 - accuracy: 0.9748 - val_loss: 0.3998 - val_accuracy: 0.8399\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.0823 - accuracy: 0.9693 - val_loss: 0.8536 - val_accuracy: 0.7861\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 65s 1s/step - loss: 0.0635 - accuracy: 0.9797 - val_loss: 0.7746 - val_accuracy: 0.7933\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 65s 1s/step - loss: 0.0459 - accuracy: 0.9819 - val_loss: 0.5714 - val_accuracy: 0.7948\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 64s 1s/step - loss: 0.0563 - accuracy: 0.9836 - val_loss: 0.6821 - val_accuracy: 0.7642\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 63s 1s/step - loss: 0.0561 - accuracy: 0.9819 - val_loss: 0.9846 - val_accuracy: 0.8341\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 62s 1s/step - loss: 0.0457 - accuracy: 0.9785 - val_loss: 1.2819 - val_accuracy: 0.7103\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 61s 1s/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 1.2313 - val_accuracy: 0.7686\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.0328 - accuracy: 0.9883 - val_loss: 0.7206 - val_accuracy: 0.7758\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 58s 1s/step - loss: 0.0396 - accuracy: 0.9834 - val_loss: 0.4208 - val_accuracy: 0.8035\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 61s 1s/step - loss: 0.0591 - accuracy: 0.9797 - val_loss: 0.2502 - val_accuracy: 0.8035\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 2.7799 - val_accuracy: 0.6958\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.7638 - val_accuracy: 0.7918\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0253 - accuracy: 0.9940 - val_loss: 3.2157 - val_accuracy: 0.6958\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0689 - accuracy: 0.9831 - val_loss: 3.0120 - val_accuracy: 0.7069\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0244 - accuracy: 0.9940 - val_loss: 4.2705 - val_accuracy: 0.6798\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 3.9382 - val_accuracy: 0.6681\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0278 - accuracy: 0.9895 - val_loss: 0.5321 - val_accuracy: 0.8748\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 3.1551 - val_accuracy: 0.7001\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 1.0471 - val_accuracy: 0.7948\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 65s 1s/step - loss: 0.0465 - accuracy: 0.9895 - val_loss: 4.3089 - val_accuracy: 0.7031\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 63s 1s/step - loss: 0.0295 - accuracy: 0.9878 - val_loss: 3.0858 - val_accuracy: 0.6870\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 66s 1s/step - loss: 0.0397 - accuracy: 0.9910 - val_loss: 4.1391 - val_accuracy: 0.7263\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 61s 1s/step - loss: 0.0294 - accuracy: 0.9924 - val_loss: 4.4728 - val_accuracy: 0.6521\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 64s 1s/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 1.9884 - val_accuracy: 0.7147\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 61s 1s/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.7057 - val_accuracy: 0.9141\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 66s 1s/step - loss: 0.0381 - accuracy: 0.9870 - val_loss: 3.2855 - val_accuracy: 0.6943\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 62s 1s/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 3.7867 - val_accuracy: 0.6806\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 65s 1s/step - loss: 0.0488 - accuracy: 0.9921 - val_loss: 2.1133 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "45/45 [==============================] - 66s 1s/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 2.7251 - val_accuracy: 0.7118\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 62s 1s/step - loss: 0.0625 - accuracy: 0.9865 - val_loss: 4.8130 - val_accuracy: 0.6477\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 62s 1s/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 2.1261 - val_accuracy: 0.7293\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 66s 1s/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 1.6793 - val_accuracy: 0.7176\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 4.7939 - val_accuracy: 0.6739\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 67s 1s/step - loss: 0.0379 - accuracy: 0.9895 - val_loss: 4.3490 - val_accuracy: 0.7205\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 64s 1s/step - loss: 0.0209 - accuracy: 0.9921 - val_loss: 3.1806 - val_accuracy: 0.7467\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 70s 2s/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 2.3312 - val_accuracy: 0.6870\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.0320 - accuracy: 0.9951 - val_loss: 3.9662 - val_accuracy: 0.6929\n"
     ]
    }
   ],
   "source": [
    "#Traing The Model \n",
    "\n",
    "#Checking if the channel(RGB) is fisrt or not \n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape=(3,img_width,img_height)\n",
    "else:\n",
    "    input_shape=(img_width,img_height,3)\n",
    "    \n",
    "#Generating Datagen using ImageDataGenerator      \n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "#Rescaling test_gen images\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "                train_data_dir,\n",
    "                target_size=(img_width,img_height),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')\n",
    "\n",
    "test_generator=train_datagen.flow_from_directory(\n",
    "                validation_data_dir,\n",
    "                target_size=(img_width,img_height),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')\n",
    "\n",
    "\n",
    "model = Sequential() #Model Choosed For This Project Is Keras Sequential\n",
    "\n",
    "#First Input Layer\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#Second Input Layer\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Third Input Layer\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Model Is Flattened\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))  #Softmax activation function for more then 2 classes here we have three classes Rock,Paper,Sissors\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=train_samples // batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_generator,\n",
    "                   validation_steps=test_samples // batch_size)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"rock_paper_sissors_json.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('rock_paper_sissors.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
